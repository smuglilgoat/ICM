{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e49a85f7",
   "metadata": {},
   "source": [
    "# TD IVIM : Pré-traitement d'images cardiaques #\n",
    "\n",
    "Le pré-traitement est une étape fondamentale pour l'analyse d'images médicales afin d'homogénéiser une base de données ( contrast, valeurs extrêmes, dimensions etc... ) et / ou de simplifier un problème ( isolement d'une région d'intérêt, atténuation d'artéfacts, extraction de caractéristiques \"features\" etc... ). Ce faisant, on retrouve des méthodes de pré-traitement dédiées à des modalités d'images ( IRM, US, CT ... ), des régions ( organes, tissus ... ) et des applications ( segmentation, classification, détection etc... ).\n",
    "\n",
    "Le but de ce TD-TP est de se familiariser avec les spécificités du pré-traitement d'images médicales à l'aide d'une application classique, l'imagerie cardiaque, pour laquelle une base de données publiques en imagerie ultrasonore est présentée. Nous utiliserons Python, un langage de programmation très utilisé en traitement d'image et science des données, y compris dans le domaine médical.\n",
    "\n",
    "## I. Imagerie ultrasonore ##\n",
    "\n",
    "L'imagerie ultrasonore est privilégiée en cardiologie pour effectuer le pré-diagnostique cardiaque car elle possède une haute résolution temporelle (adaptée à l'étude d'un organe dynamique) et que l'examen est à la fois rapide et peu coûteux. \n",
    "\n",
    "#### CAMUS dataset ####\n",
    "\n",
    "La base de données CAMUS (Cardiac Acquisitions for Multi-Structure Ultrasound image Segmentation) contient les vues apicales 2 chambres (2CH) et 4 chambres (4CH) d'au moins un cycle cardiaque de 500 patients. Les instants de fin diastole (ED) et de fin systole (ES) ont été annotés par un expert afin d'avoir les segmentations de 3 structures : le ventricule gauche, l'oreillette gauche et le myocarde. Les données ont été converties du format DICOM au format MHD (MetaImage MetaHeader file) afin de séparer les méta-données des images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "db3fcc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import skimage as sk\n",
    "import skimage.io as io\n",
    "from skimage.restoration import denoise_wavelet, estimate_sigma\n",
    "from skimage.filters.rank import median\n",
    "from skimage.feature import hog\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "ROOT_DIR = os.path.abspath(os.curdir)\n",
    "CAMUS_DIR = os.path.join(ROOT_DIR, \"CAMUS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8582b4d6",
   "metadata": {},
   "source": [
    "#### Prise en main des données ####\n",
    "\n",
    "1. Étudiez la fonction \"load_camus_mhd\" puis utilisez-la afin de visualiser l'image 2CH en ES du patient 17 et l'image 4CH en ED du patient 42. Qu' observez-vous ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eba36c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_camus_mhd(dataset_path, pid, view, ti, display=False):\n",
    "    \"\"\"\n",
    "    :param dataset_path: path to the CAMUS dataset\n",
    "    :param pid: patient ID number\n",
    "    :param view: '2CH' or '4CH' view\n",
    "    :param ti: 'ES' or 'ED' instant\n",
    "    :return: the corresponding raw 2D image\n",
    "    \"\"\"\n",
    "\n",
    "    pid = str(pid).zfill(4)  # put ID on 4 digits\n",
    "    pname = 'patient' + pid\n",
    "    data_path = os.path.join(dataset_path, pname)\n",
    "    im_name = os.path.join(data_path, pname + '_' + view + '_' + ti)\n",
    "    img = io.imread(im_name + '.mhd', plugin='simpleitk')[0]  # load image with SimpleITK\n",
    "\n",
    "    if display:\n",
    "        plt.figure()  # display with grey levels\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.show(block=False)\n",
    "        plt.savefig(im_name+'.png')\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154f5ad8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e19cd8d5",
   "metadata": {},
   "source": [
    "\n",
    "2. Étudiez la fonction \"display_mask_camus\" puis visualisez les 4 images du patient 17 puis 42 avec les structures annotées. Pourquoi est-ce que la segmentation du coeur est une tâche particulièrement difficile en ultrasons ?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ef37d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_mask_camus(dataset_path, pid, view, ti, csize=5, display=False):\n",
    "    \"\"\"\n",
    "    :param dataset_path: path to the CAMUS dataset\n",
    "    :param pid: patient ID number\n",
    "    :param view: '2CH' or '4CH' view\n",
    "    :param ti: 'ES' or 'ED' instant\n",
    "    :param csize: contour size in px\n",
    "    \"\"\"\n",
    "\n",
    "    pid = str(pid).zfill(4)  # put ID on 4 digits\n",
    "    pname = 'patient' + pid\n",
    "    data_path = os.path.join(dataset_path, pname)\n",
    "    im_name = os.path.join(data_path, pname + '_' + view + '_' + ti)\n",
    "    mask_name = os.path.join(data_path, pname + '_' + view + '_' + ti)\n",
    "\n",
    "    img = io.imread(im_name + '.mhd', plugin='simpleitk')[0]  # load image with SimpleITK\n",
    "    mask = io.imread(mask_name + '_gt.mhd', plugin='simpleitk')[0]  # load mask with SimpleITK\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # extract frontier between neighbouring structures\n",
    "    selem = sk.morphology.disk(csize)  # structuring element\n",
    "    struct1 = (sk.filters.rank.minimum(mask, selem) == 1) & (sk.filters.rank.maximum(mask, selem) == 2)  # LV\n",
    "    struct2 = (sk.filters.rank.minimum(mask, selem) == 0) & (sk.filters.rank.maximum(mask, selem) == 2)  # Myocardium\n",
    "    struct3 = (sk.filters.rank.minimum(mask, selem) == 0) & (sk.filters.rank.maximum(mask, selem) == 3)  # LA\n",
    "\n",
    "    # associate each structure to a color\n",
    "    img[struct1, :] = np.asarray([255, 0, 0])\n",
    "    img[struct2, :] = np.asarray([0, 255, 0])\n",
    "    img[struct3, :] = np.asarray([0, 0, 255])\n",
    "\n",
    "    # Show result\n",
    "    if display:\n",
    "        plt.figure()\n",
    "        plt.imshow(img)\n",
    "        plt.show(block=False)\n",
    "        plt.savefig(im_name + 'with_mask.png')\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fdd3f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc92ab1c",
   "metadata": {},
   "source": [
    "3. Chargez les images 2CH des patients 17, 42, 256 et 326. Comparez les valeurs minimales et maximales des images ainsi que leur taille. Que constatez-vous ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db529a68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c5c2940",
   "metadata": {},
   "source": [
    "4. Utilisez la fonction \"intensity_and_size_equalization\" pour harmoniser les images en terme d'intensité et de dimensions. Expliquez pourquoi cette étape est primordiale en particulier dans l'optique d'utiliser des méthodes d'apprentissage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ec8af67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intensity_and_size_equalization(img, size, display=False):\n",
    "    \"\"\"\n",
    "    :param img: image to pre-process\n",
    "    :param size : target size\n",
    "    :return: the pre-processed image\n",
    "    \"\"\"\n",
    "\n",
    "    img = sk.transform.resize(img, size, order=1)  # resize image with bilinear interpolation\n",
    "    img_out = 255 * (img - np.min(img)) / (np.max(img) - np.min(img))  # intensity normalization on uint8 images\n",
    "\n",
    "    # Show result\n",
    "    if display:\n",
    "        plt.figure()  # display\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.show(block=False)\n",
    "    return np.uint8(img_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279deab1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca1d1570",
   "metadata": {},
   "source": [
    "#### Débruitage à base d'ondelettes ####\n",
    "\n",
    "La texture des images ultrasonores, appelée \"speckle\", est souvent assimilée à du bruit rendant la détection de contours difficile. Une des solutions communément adoptée pour l'atténuer est le débruitage par ondelettes (le speckle est alors assimilé à un bruit gaussien), qui donne de meilleurs résultats qu'un simple filtre passe-bas.\n",
    "\n",
    "5. Étudiez la fonction \"us_denoising\" puis appliquez la avec les paramètres par défaut sur l'image 2CH du patient 256 en ES. Qu'observez-vous ? \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fa887def",
   "metadata": {},
   "outputs": [],
   "source": [
    "def us_denoising(img, method='median', scale=5, display=False):\n",
    "    \"\"\"\n",
    "    :param img: image to filter\n",
    "    :param method : type of filters 'wavelets' or median filter by default\n",
    "    :return: the filtered image\n",
    "    \"\"\"\n",
    "\n",
    "    if method == 'wavelets':\n",
    "\n",
    "        sigma = estimate_sigma(img)  # Estimate the average noise standard deviation across color channels.\n",
    "        img_out = denoise_wavelet(img, sigma=scale * sigma, wavelet='db2',\n",
    "                                  method='BayesShrink')  # Use orthogonal wavelets (db)\n",
    "\n",
    "    else:\n",
    "\n",
    "        # return local median of an image\n",
    "        selem = sk.morphology.disk(scale)  # structuring element\n",
    "        img_out = median(img, selem)\n",
    "\n",
    "    # Show result\n",
    "    if display:\n",
    "        plt.figure()  # display\n",
    "        plt.imshow(img_out, cmap='gray')\n",
    "        plt.show(block=False)\n",
    "    return img_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857bc381",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75bac27d",
   "metadata": {},
   "source": [
    "6. Jouez avec les paramètres jusqu'à obtenir une configuration qui vous semble donner de bons résultats de filtrage du speckle dans le ventricule gauche. Comment procéderiez-vous pour trouver la valeur optimale de ces hyper-paramètres sur toute la base de données ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ff0020",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2792bf61",
   "metadata": {},
   "source": [
    "#### Application à l' extraction de caractéristiques de bords ####\n",
    "\n",
    "\n",
    "L'histogramme de gradients orientés (HOG) est une caractéristique très utilisée pour la détection d'objets en vision par ordinateur, dans laquelle un bord n'est pas seulement associé à une intensité mais également à une direction.\n",
    "\n",
    "7. Étudiez la fonction \"HOG\" avant de l'appliquer sur l'image 2CH du patient 256 sans débruitage, puis après débruitage. Qu'observez-vous ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6919da57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hog(img, orientations=4, patch_size=(16, 16), display=True):\n",
    "    \"\"\"\n",
    "    :param img: image to extract features from\n",
    "    :param orientations : number of orientations to consider\n",
    "    :return: the HOG features (we won't use them though)\n",
    "    \"\"\"\n",
    "\n",
    "    # creating hog features\n",
    "    fd, hog_image = hog(img, orientations, patch_size, visualize=True)\n",
    "\n",
    "    if display:\n",
    "        plt.figure()  # display\n",
    "        plt.imshow(hog_image, cmap='gray')\n",
    "        plt.show(block=False)\n",
    "\n",
    "    return fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0583f385",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b557448",
   "metadata": {},
   "source": [
    "8. Affichez les HOG calculés en changeant la taille du patch. Selon vous, quelles échelles apparaissent comme les plus utiles pour détecter le ventricule gauche ?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6871c281",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6143ad9",
   "metadata": {},
   "source": [
    "#### Extraction de régions d'intérêt ####\n",
    "\n",
    "Il est commun en imagerie médicale de concentrer le traitement autour d'une zone d'intérêt (ROI) afin d'améliorer la précision, que ce soit pour de la détection, segmentation ou classification. En effet cela permet de normaliser le context et de s'affranchir d'une variabilité qui pourrait confondre les algorithmes. \n",
    "\n",
    "9. En utilisant la fonction extract_roi, proposez un algorithme permettant d'isoler le ventricule gauche (label=1) avec une marge de 10 px sur une image de CAMUS. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "edcd772a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_roi(img, mask, label=2, margin=0, display=False):\n",
    "    \"\"\"\n",
    "    :param img: image to extract features from\n",
    "    :param mask : masque de segmentation\n",
    "    :param label : Structure to extract\n",
    "    :param margin : margin in px\n",
    "    :return: the ROI\n",
    "    \"\"\"\n",
    "\n",
    "    # get the bounding box coordinates\n",
    "    mask[mask != label] = 0  # isolate structure\n",
    "    mask = sk.transform.resize(mask, img.shape, order=0)  # resize with nearest neighbour interpolation\n",
    "    edge_ind = np.argwhere(mask > 0)\n",
    "    xmin, xmax = np.min(edge_ind[:, 0]), np.max(edge_ind[:, 0])\n",
    "    ymin, ymax = np.min(edge_ind[:, 1]), np.max(edge_ind[:, 1])\n",
    "\n",
    "    # apply margin and check image limits\n",
    "    ds = int(margin / 2)\n",
    "    xmin, xmax = xmin - ds, xmax + ds\n",
    "    ymin, ymax = ymin - ds, ymax + ds\n",
    "    xmin, xmax = np.max([0, xmin]), np.min([xmax, img.shape[0] - 1])\n",
    "    ymin, ymax = np.max([0, ymin]), np.min([ymax, img.shape[1] - 1])\n",
    "\n",
    "    roi = img[xmin:xmax, ymin:ymax]\n",
    "\n",
    "    if display:\n",
    "        plt.figure()  # display\n",
    "        plt.imshow(roi, cmap='gray')\n",
    "        plt.show(block=False)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2e01f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90beec39",
   "metadata": {},
   "source": [
    "10. Comment procéderiez-vous si vous n'aviez pas accès aux masques de segmentation ? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3cbc21",
   "metadata": {},
   "source": [
    "11. Selon le temps qu'il vous reste, vous pouvez proposer une étape supplémentaire de pré-traitement de ces données."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
